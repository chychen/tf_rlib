{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1121 10:04:32.767725 140523926275904 __init__.py:115] init flags\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import tf_rlib\n",
    "from tf_rlib.runners import SegmentationRunner\n",
    "FLAGS = tf_rlib.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 10:04:34.986124 140523926275904 tools.py:12] purged all logs under :/results\n",
      "W1121 10:04:34.987115 140523926275904 tools.py:23] update CUDA_VISIBLE_DEVICES=0\n",
      "I1121 10:04:38.749948 140523926275904 tf_datasets.py:67] mean:[0.14852086 0.13537924 0.17429093 0.47761193], std:[0.24763672 0.231558   0.27477    0.48867777]\n",
      "I1121 10:04:38.751918 140523926275904 tf_datasets.py:69] data size:(536, 256, 256, 4), label size\"(536, 256, 256, 2)\n",
      "I1121 10:04:40.018673 140523926275904 tools.py:88] FLAGS: --logtostderr=False\n",
      "I1121 10:04:40.020092 140523926275904 tools.py:88] FLAGS: --alsologtostderr=False\n",
      "I1121 10:04:40.021414 140523926275904 tools.py:88] FLAGS: --log_dir=\n",
      "I1121 10:04:40.022725 140523926275904 tools.py:88] FLAGS: --v=0\n",
      "I1121 10:04:40.023997 140523926275904 tools.py:88] FLAGS: --verbosity=0\n",
      "I1121 10:04:40.025169 140523926275904 tools.py:88] FLAGS: --stderrthreshold=fatal\n",
      "I1121 10:04:40.026398 140523926275904 tools.py:88] FLAGS: --showprefixforinfo=True\n",
      "I1121 10:04:40.027605 140523926275904 tools.py:88] FLAGS: --run_with_pdb=False\n",
      "I1121 10:04:40.028866 140523926275904 tools.py:88] FLAGS: --pdb_post_mortem=False\n",
      "I1121 10:04:40.030094 140523926275904 tools.py:88] FLAGS: --run_with_profiling=False\n",
      "I1121 10:04:40.031291 140523926275904 tools.py:88] FLAGS: --profile_file=None\n",
      "I1121 10:04:40.032662 140523926275904 tools.py:88] FLAGS: --use_cprofile_for_profiling=True\n",
      "I1121 10:04:40.033712 140523926275904 tools.py:88] FLAGS: --only_check_args=False\n",
      "I1121 10:04:40.034745 140523926275904 tools.py:88] FLAGS: --op_conversion_fallback_to_while_loop=False\n",
      "I1121 10:04:40.035930 140523926275904 tools.py:88] FLAGS: --test_random_seed=301\n",
      "I1121 10:04:40.037002 140523926275904 tools.py:88] FLAGS: --test_srcdir=\n",
      "I1121 10:04:40.038196 140523926275904 tools.py:88] FLAGS: --test_tmpdir=/tmp/absl_testing\n",
      "I1121 10:04:40.039454 140523926275904 tools.py:88] FLAGS: --test_randomize_ordering_seed=None\n",
      "I1121 10:04:40.040406 140523926275904 tools.py:88] FLAGS: --xml_output_file=\n",
      "I1121 10:04:40.041594 140523926275904 tools.py:88] FLAGS: --log_level=DEBUG\n",
      "I1121 10:04:40.042696 140523926275904 tools.py:88] FLAGS: --profile=False\n",
      "I1121 10:04:40.043958 140523926275904 tools.py:88] FLAGS: --purge_logs=False\n",
      "I1121 10:04:40.045074 140523926275904 tools.py:88] FLAGS: --current_time=20191121-180432\n",
      "I1121 10:04:40.046273 140523926275904 tools.py:88] FLAGS: --local_path=/results\n",
      "I1121 10:04:40.047273 140523926275904 tools.py:88] FLAGS: --log_path=/results/default/20191121-180432/log\n",
      "I1121 10:04:40.048404 140523926275904 tools.py:88] FLAGS: --path_postfix=\n",
      "I1121 10:04:40.049434 140523926275904 tools.py:88] FLAGS: --save_path=/results/default/20191121-180432/ckpt\n",
      "I1121 10:04:40.050372 140523926275904 tools.py:88] FLAGS: --exp_name=default\n",
      "I1121 10:04:40.051460 140523926275904 tools.py:88] FLAGS: --comment=None\n",
      "I1121 10:04:40.052670 140523926275904 tools.py:88] FLAGS: --benchmark_runner=None\n",
      "I1121 10:04:40.053645 140523926275904 tools.py:88] FLAGS: --gpus=0\n",
      "I1121 10:04:40.054672 140523926275904 tools.py:88] FLAGS: --amp=False\n",
      "I1121 10:04:40.055887 140523926275904 tools.py:88] FLAGS: --xla=False\n",
      "I1121 10:04:40.056907 140523926275904 tools.py:88] FLAGS: --out_dim=2\n",
      "I1121 10:04:40.058045 140523926275904 tools.py:88] FLAGS: --dim=2\n",
      "I1121 10:04:40.059046 140523926275904 tools.py:88] FLAGS: --lr=0.0001\n",
      "I1121 10:04:40.060305 140523926275904 tools.py:88] FLAGS: --epochs=20\n",
      "I1121 10:04:40.061307 140523926275904 tools.py:88] FLAGS: --warmup=5\n",
      "I1121 10:04:40.062455 140523926275904 tools.py:88] FLAGS: --bs=32\n",
      "I1121 10:04:40.063372 140523926275904 tools.py:88] FLAGS: --adam_beta_1=0.9\n",
      "I1121 10:04:40.064321 140523926275904 tools.py:88] FLAGS: --adam_beta_2=0.999\n",
      "I1121 10:04:40.065271 140523926275904 tools.py:88] FLAGS: --adam_epsilon=1e-08\n",
      "I1121 10:04:40.066303 140523926275904 tools.py:88] FLAGS: --l1=0.0\n",
      "I1121 10:04:40.067359 140523926275904 tools.py:88] FLAGS: --l2=0.0\n",
      "I1121 10:04:40.068340 140523926275904 tools.py:88] FLAGS: --wd=0.0\n",
      "I1121 10:04:40.069321 140523926275904 tools.py:88] FLAGS: --kernel_initializer=he_normal\n",
      "I1121 10:04:40.070280 140523926275904 tools.py:88] FLAGS: --bias_initializer=zeros\n",
      "I1121 10:04:40.071445 140523926275904 tools.py:88] FLAGS: --padding=same\n",
      "I1121 10:04:40.072415 140523926275904 tools.py:88] FLAGS: --conv_act=ReLU\n",
      "I1121 10:04:40.073378 140523926275904 tools.py:88] FLAGS: --interpolation=nearest\n",
      "I1121 10:04:40.074345 140523926275904 tools.py:88] FLAGS: --conv_norm=BatchNormalization\n",
      "I1121 10:04:40.075442 140523926275904 tools.py:88] FLAGS: --bn_momentum=0.9\n",
      "I1121 10:04:40.076397 140523926275904 tools.py:88] FLAGS: --bn_epsilon=1e-05\n",
      "I1121 10:04:40.077376 140523926275904 tools.py:88] FLAGS: --conv_pooling=AveragePooling\n",
      "I1121 10:04:40.078403 140523926275904 tools.py:88] FLAGS: --global_pooling=GlobalAveragePooling\n",
      "I1121 10:04:40.079619 140523926275904 tools.py:88] FLAGS: --model_alpha=200\n",
      "I1121 10:04:40.080633 140523926275904 tools.py:88] FLAGS: --depth=None\n",
      "I1121 10:04:40.081623 140523926275904 tools.py:88] FLAGS: --bottleneck=True\n",
      "I1121 10:04:40.082661 140523926275904 tools.py:88] FLAGS: --filters_mode=small\n",
      "I1121 10:04:40.083837 140523926275904 tools.py:88] FLAGS: --?=False\n",
      "I1121 10:04:40.084956 140523926275904 tools.py:88] FLAGS: --help=False\n",
      "I1121 10:04:40.085928 140523926275904 tools.py:88] FLAGS: --helpshort=False\n",
      "I1121 10:04:40.087208 140523926275904 tools.py:88] FLAGS: --helpfull=False\n",
      "I1121 10:04:40.088527 140523926275904 tools.py:88] FLAGS: --helpxml=False\n",
      "W1121 10:04:40.089566 140523926275904 tools.py:90] enable --xla=True is recommended for ~10% speedup.\n",
      "I1121 10:04:40.101380 140523926275904 runner.py:32] Number of devices: 1\n",
      "I1121 10:04:45.777039 140523926275904 runner.py:53] unet model contains 8644546 trainable variables.\n"
     ]
    }
   ],
   "source": [
    "tf_rlib.utils.purge_logs()\n",
    "tf_rlib.utils.set_gpus('0')\n",
    "tf_rlib.utils.set_logging('DEBUG')\n",
    "\n",
    "FLAGS.lr = 1e-4\n",
    "FLAGS.dim = 2\n",
    "FLAGS.out_dim = 2\n",
    "FLAGS.bs = 32\n",
    "FLAGS.epochs = 20\n",
    "\n",
    "FLAGS.bottleneck=True\n",
    "\n",
    "datasets = tf_rlib.datasets.get_cell()\n",
    "runner = SegmentationRunner(*datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d0116ac99b4f1cb871f248a7772626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8fd4a26037e415bb08286991112b10d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='valid', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1121 10:05:19.191913 140523926275904 runner.py:183] time cost for first epoch: 26.076648235321045 sec\n",
      "I1121 10:05:19.212405 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8243\n",
      "epoch: 1  train_loss: 2.4365  train_dice_coef: 0.7321  valid_loss: 0.8851  valid_dice_coef: 0.8243  samples/sec: 25.7924\n",
      "\n",
      "I1121 10:05:28.609921 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8509\n",
      "epoch: 2  train_loss: 1.9196  train_dice_coef: 0.7454  valid_loss: 0.5412  valid_dice_coef: 0.8509  samples/sec: 71.8098\n",
      "\n",
      "I1121 10:05:37.922548 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8739\n",
      "epoch: 3  train_loss: 0.5818  train_dice_coef: 0.8553  valid_loss: 0.2896  valid_dice_coef: 0.8739  samples/sec: 72.4791\n",
      "\n",
      "I1121 10:05:47.086619 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8812\n",
      "epoch: 4  train_loss: 0.3607  train_dice_coef: 0.8752  valid_loss: 0.2477  valid_dice_coef: 0.8812  samples/sec: 73.6320\n",
      "\n",
      "I1121 10:05:56.300868 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8840\n",
      "epoch: 5  train_loss: 0.3020  train_dice_coef: 0.8785  valid_loss: 0.1980  valid_dice_coef: 0.8840  samples/sec: 73.2558\n",
      "\n",
      "I1121 10:06:05.487337 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8858\n",
      "epoch: 6  train_loss: 0.2741  train_dice_coef: 0.8797  valid_loss: 0.1740  valid_dice_coef: 0.8858  samples/sec: 73.4851\n",
      "\n",
      "I1121 10:06:14.669117 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8864\n",
      "epoch: 7  train_loss: 0.2392  train_dice_coef: 0.8814  valid_loss: 0.1612  valid_dice_coef: 0.8864  samples/sec: 73.5218\n",
      "\n",
      "I1121 10:06:28.038168 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8866\n",
      "epoch: 8  train_loss: 0.2376  train_dice_coef: 0.8814  valid_loss: 0.1530  valid_dice_coef: 0.8866  samples/sec: 50.4297\n",
      "\n",
      "I1121 10:06:36.023774 140523926275904 metrics_manager.py:78] \n",
      "epoch: 9  train_loss: 0.2061  train_dice_coef: 0.8840  valid_loss: 0.1613  valid_dice_coef: 0.8864  samples/sec: 84.6027\n",
      "\n",
      "I1121 10:06:45.252161 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8876\n",
      "epoch: 10  train_loss: 0.2116  train_dice_coef: 0.8840  valid_loss: 0.1451  valid_dice_coef: 0.8876  samples/sec: 73.1635\n",
      "\n",
      "I1121 10:06:54.543318 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8876\n",
      "epoch: 11  train_loss: 0.1946  train_dice_coef: 0.8850  valid_loss: 0.1418  valid_dice_coef: 0.8876  samples/sec: 72.6395\n",
      "\n",
      "I1121 10:07:08.026244 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8879\n",
      "epoch: 12  train_loss: 0.1843  train_dice_coef: 0.8855  valid_loss: 0.1353  valid_dice_coef: 0.8879  samples/sec: 49.9887\n",
      "\n",
      "I1121 10:07:17.091684 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8885\n",
      "epoch: 13  train_loss: 0.1704  train_dice_coef: 0.8869  valid_loss: 0.1294  valid_dice_coef: 0.8885  samples/sec: 74.4676\n",
      "\n",
      "I1121 10:07:25.145592 140523926275904 metrics_manager.py:78] \n",
      "epoch: 14  train_loss: 0.1684  train_dice_coef: 0.8868  valid_loss: 0.1298  valid_dice_coef: 0.8883  samples/sec: 83.8630\n",
      "\n",
      "I1121 10:07:34.367042 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8885\n",
      "epoch: 15  train_loss: 0.1684  train_dice_coef: 0.8865  valid_loss: 0.1289  valid_dice_coef: 0.8885  samples/sec: 73.1909\n",
      "\n",
      "I1121 10:07:48.738201 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8886\n",
      "epoch: 16  train_loss: 0.1722  train_dice_coef: 0.8858  valid_loss: 0.1262  valid_dice_coef: 0.8886  samples/sec: 46.8862\n",
      "\n",
      "I1121 10:07:57.852618 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8889\n",
      "epoch: 17  train_loss: 0.1601  train_dice_coef: 0.8875  valid_loss: 0.1246  valid_dice_coef: 0.8889  samples/sec: 74.0328\n",
      "\n",
      "I1121 10:08:05.729893 140523926275904 metrics_manager.py:78] \n",
      "epoch: 18  train_loss: 0.1632  train_dice_coef: 0.8870  valid_loss: 0.1256  valid_dice_coef: 0.8888  samples/sec: 85.7457\n",
      "\n",
      "I1121 10:08:13.716214 140523926275904 metrics_manager.py:78] \n",
      "epoch: 19  train_loss: 0.1692  train_dice_coef: 0.8862  valid_loss: 0.1247  valid_dice_coef: 0.8889  samples/sec: 84.5950\n",
      "\n",
      "I1121 10:08:22.829308 140523926275904 metrics_manager.py:78] Best Performance at dice_coef: 0.8890\n",
      "epoch: 20  train_loss: 0.1586  train_dice_coef: 0.8875  valid_loss: 0.1238  valid_dice_coef: 0.8890  samples/sec: 74.0662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "runner.fit(20, lr=FLAGS.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
